<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting started · StatReg.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>StatReg.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li class="current"><a class="toctext" href>Getting started</a><ul class="internal"><li><a class="toctext" href="#Installation-1">Installation</a></li><li><a class="toctext" href="#Usage-1">Usage</a></li></ul></li><li><a class="toctext" href="../users_guide/">User&#39;s Guide</a></li><li><a class="toctext" href="../examples/">Examples</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Getting started</a></li></ul><a class="edit-page" href="https://github.com/mipt-npm/StatReg.jl/blob/master/docs/src/getting_started.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Getting started</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Getting-started-1" href="#Getting-started-1">Getting started</a></h1><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><p>To install StatReg.jl, start up Julia and type the following code-snipped into the REPL.</p><pre><code class="language-julia">import Pkg
Pkg.clone(&quot;https://github.com/mipt-npm/StatReg.jl.git&quot;)</code></pre><h2><a class="nav-anchor" id="Usage-1" href="#Usage-1">Usage</a></h2><p>Let&#39;s consider the simplest case of deconvolution. The function to be reconstructed <span>$\varphi(x)$</span> is the sum of two Gaussian distributions.</p><pre><code class="language-julia">using PyCall

a = 0
b = 6.

function phi(x::Real)
    mu1 = 2.
    mu2 = 4.
    n1 = 4.
    n2 = 2.
    sig1 = 0.4
    sig2 = 0.5
    norm(n, mu, sig, x) = n / sqrt(2 * pi*sig^2) * exp(-(x - mu)^2 / (2 * sig^2))
    return norm(n1, mu1, sig1, x) + norm(n2, mu2, sig2, x)
end

x = collect(range(a, stop=b, length=300))

myplot = plot(x, phi.(x))</code></pre><p><img src="../img/real_phi.png" alt="real_phi"/></p><p>After integration we get data and errors. <code>kernel</code> - kernel function, <code>y</code> - measurement points, <code>f</code> - data points, <code>sig</code> - data errors.</p><pre><code class="language-julia">kernel(x::Real, y::Real) = getOpticsKernels(&quot;gaussian&quot;)(x, y)

convolution = y -&gt; quadgk(x -&gt; kernel(x,y) * phi(x), a, b, rtol=10^-5, maxevals=10^7)[1]
y = collect(range(a, stop=b, length=30))
ftrue = convolution.(y)

sig = 0.05*ftrue + [0.01 for i = 1:Base.length(ftrue)]

using Compat, Random, Distributions
noise = []
Random.seed!(1234)
for sigma in sig
    n = rand(Normal(0., sigma), 1)[1]
    push!(noise, n)
end

f = ftrue + noise
plot(y, f, title=&quot;Integrated function&quot;,label=[&quot;f(y)&quot;])</code></pre><p><img src="../img/integrated.png" alt="integrated"/></p><p>Let&#39;s proceed to the reconstruction.</p><p>To reconstruct function you need to load data <span>$f(y)$</span> and data errors <span>$\delta f(y)$</span> and define kernel <span>$K(x, y)$</span>. There are two possibilities: use vector &amp; matrix form or continuous form. In the first case <span>$K(x, y)$</span> is matrix <span>$n \times m$</span>, <span>$f(y)$</span> and <span>$\delta f(y)$</span> - n-dimensional vectors. In the second case <span>$K(x, y)$</span> is a function, <span>$f(y)$</span> and <span>$\delta f(y)$</span> can be either functions or vectors. If they are functions, knot vector <span>$y$</span> should be specified (points where the measurement is taken).</p><ul><li><p>We have already defined all needed data (<code>y</code> is a list of measurement points, <code>f</code> is a list of function values at these points, <code>sig</code> is a list of error in these points)</p></li><li><p>Basis:</p></li></ul><p>We will use Cubic Spline Basis with knots in data points and zero boundary conditions on both sides.</p><pre><code class="language-julia">basis = CubicSplineBasis(y, &quot;dirichlet&quot;)
for func in basis.basis_functions
    plot(x, func.f.(x))
end</code></pre><p><img src="../img/cubic_spline_basis.png" alt="cubic_spline_basis"/></p><ul><li>Model:</li></ul><p>To reconstruct the function, we use matrix of the second derivatives as a prior information. Then we choose a solution model. It requires basis and a set of matrices that contain prior information, in our case it is smoothness. The method we use is called &quot;EmpiricalBayes&quot;, it means that <span>$\alpha$</span> is chosen as a maximum of posterior probability <span>$P(\alpha | f)$</span>. Also, it is important to set higher and lower bounds of <span>$\alpha$</span> and initial value for optimisation.</p><pre><code class="language-julia">Omega = omega(basis, 2)
model = GaussErrorUnfolder(basis, [Omega], &quot;EmpiricalBayes&quot;, nothing, [1e-8], [10.], [0.3])</code></pre><ul><li>Reconstruction:</li></ul><p>To reconstruct the function we use <span>$solve()$</span> that returns dictionary containing coefficients of basis function in the sum <span>$\varphi(x) = \sum_{k=1}^N coeff_n \psi_n(x)$</span>, their errors <span>$errors_n$</span> (<span>$\delta \varphi =  \sum_{k=1}^N errors_n \psi_n(x)$</span>) and optimal parameter of smoothness <span>$\alpha$</span>.</p><pre><code class="language-julia">result = solve(model, kernel, f, sig, y)</code></pre><ul><li>Results</li></ul><p>Representation of results in a convenient way is possible with <code>PhiVec</code>:</p><pre><code class="language-julia">phivec = PhiVec(result, basis)

phi_reconstructed = phivec.phi_function.(x)
phi_reconstructed_errors = phivec.error_function.(x)

plot(x, phi_reconstructed, ribbon=phi_reconstructed_errors, fillalpha=0.3, label=&quot;Reconstructed function with errors&quot;)
plot!(x, phi.(x), label=&quot;Real function&quot;)</code></pre><p><img src="../img/reconstructed.png" alt="reconstructed"/></p><p>Full notebook you can find in <code>examples/getting_started.ipynb</code></p><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../users_guide/"><span class="direction">Next</span><span class="title">User&#39;s Guide</span></a></footer></article></body></html>
